{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "003ef49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class TopKSparse(nn.Module):\n",
    "    def __init__(self, token_dim, code_dim, discrete_size,\n",
    "                 randomized=True, random_p=0.1):\n",
    "        super().__init__()\n",
    "        self.token_dim = token_dim\n",
    "        self.code_dim = code_dim\n",
    "        self.discrete_size = discrete_size\n",
    "        self.sparsity_ratio = np.log2(discrete_size) / 16\n",
    "        self.randomized = randomized\n",
    "        self.random_p = random_p\n",
    "\n",
    "    def compress(self, x):\n",
    "        x_shape = x.shape                        # [B,S,H]\n",
    "        flattened_x = x.view(-1, x.shape[-1])        # [B*S,H]\n",
    "        H = flattened_x.shape[1]\n",
    "\n",
    "        # ---------- 1. Top-K ----------\n",
    "        k = max(1, int(self.sparsity_ratio * H))\n",
    "        _, topk_idx = torch.topk(flattened_x.abs(), k, dim=1)\n",
    "\n",
    "        mask = torch.zeros_like(flattened_x, dtype=torch.bool)\n",
    "        mask.scatter_(1, topk_idx, True)\n",
    "\n",
    "        # ---------- 2. random augmentation ----------\n",
    "        if self.randomized and self.random_p > 0:\n",
    "            rand_mask = torch.rand_like(flattened_x) < self.random_p\n",
    "            mask |= rand_mask\n",
    "\n",
    "        # ---------- 3. FINAL idx ----------\n",
    "        # 每一行不同数量，需转成 ragged / packed\n",
    "        idx_list = mask.nonzero(as_tuple=False)  # [N,2] -> (row, col)\n",
    "\n",
    "        # ---------- 4. values FROM idx ----------\n",
    "        values = flattened_x[idx_list[:, 0], idx_list[:, 1]]\n",
    "\n",
    "        payload = {\n",
    "            \"indices\": idx_list,   # (row_idx, col_idx)\n",
    "            \"values\": values\n",
    "        }\n",
    "\n",
    "        aux = {\n",
    "            \"embedding_shape\": x_shape,\n",
    "            \"code_dim\": H\n",
    "        }\n",
    "\n",
    "        return payload, aux, torch.tensor(0.0, device=x.device)\n",
    "\n",
    "    def decompress(self, payload, aux):\n",
    "        indices = payload[\"indices\"]\n",
    "        values = payload[\"values\"]\n",
    "        x_shape = aux[\"embedding_shape\"]\n",
    "        H = aux[\"code_dim\"]\n",
    "\n",
    "        BxS = x_shape[0] * x_shape[1]\n",
    "        flattened_x = torch.zeros(\n",
    "            (BxS, H), device=values.device, dtype=values.dtype\n",
    "        )\n",
    "\n",
    "        flattened_x[indices[:, 0], indices[:, 1]] = values\n",
    "        return flattened_x.view(x_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7d175ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 128])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=TopKSparse(128,128,4)\n",
    "x=torch.randn(4,10,128)\n",
    "payload, aux, _=s.compress(x)\n",
    "e=s.decompress(payload, aux)\n",
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e37f3c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1115, 2])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload[\"indices\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "23a6af0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y, dim=-1, eps=1e-4):\n",
    "    dot_product = (x * y).sum(dim=dim)\n",
    "    x_norm = x.norm(p=2, dim=dim)\n",
    "    y_norm = y.norm(p=2, dim=dim)\n",
    "    return dot_product / (x_norm * y_norm + eps)\n",
    "class CosineLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CosineLoss, self).__init__()\n",
    "    def forward(self,x1,x2,target,eps=1e-3):\n",
    "        sim=cosine_similarity(x1,x2,dim=-1,eps=eps)\n",
    "        loss=1-sim\n",
    "        return(loss.sum()/loss.shape[0])\n",
    "def pack_2bit_tensor(q: torch.Tensor):\n",
    "    \"\"\"\n",
    "    q: torch.Tensor, dtype=torch.uint8, values in {0,1,2,3}\n",
    "    returns:\n",
    "        packed: torch.Tensor, dtype=torch.uint8\n",
    "        pad: int\n",
    "    \"\"\"\n",
    "    assert q.dtype == torch.uint8\n",
    "    q_shape=q.shape\n",
    "    q = q.reshape(-1)\n",
    "\n",
    "    pad = (-q.numel()) % 4\n",
    "    if pad:\n",
    "        q = torch.cat([\n",
    "            q,\n",
    "            torch.zeros(pad, dtype=q.dtype, device=q.device)\n",
    "        ])\n",
    "    else:\n",
    "        pad=0\n",
    "\n",
    "    q = q.view(-1, 4)\n",
    "    packed = (\n",
    "        (q[:, 0] << 0) |\n",
    "        (q[:, 1] << 2) |\n",
    "        (q[:, 2] << 4) |\n",
    "        (q[:, 3] << 6)\n",
    "    ).to(torch.uint8)\n",
    "\n",
    "    return packed,q_shape, pad\n",
    "\n",
    "def unpack_2bit_tensor(packed: torch.Tensor,q_shape,pad=0):\n",
    "    \"\"\"\n",
    "    packed: torch.uint8 tensor\n",
    "    pad: int\n",
    "    \"\"\"\n",
    "    assert packed.dtype == torch.uint8\n",
    "\n",
    "    q = torch.empty(\n",
    "        (packed.numel(), 4),\n",
    "        dtype=torch.uint8,\n",
    "        device=packed.device\n",
    "    )\n",
    "\n",
    "    q[:, 0] = (packed >> 0) & 0b11\n",
    "    q[:, 1] = (packed >> 2) & 0b11\n",
    "    q[:, 2] = (packed >> 4) & 0b11\n",
    "    q[:, 3] = (packed >> 6) & 0b11\n",
    "\n",
    "    q = q.view(-1)\n",
    "    if pad:\n",
    "        q = q[:-pad]\n",
    "    q=q.reshape(q_shape)\n",
    "    return q.float()\n",
    "    \n",
    "    \n",
    "def robust_minmax(X,width=3):\n",
    "    mean = X.mean()\n",
    "    std = X.std()\n",
    "    q_min = mean - width * std\n",
    "    q_max = mean + width * std\n",
    "    X_clipped = torch.clamp(X, q_min, q_max)\n",
    "    X_norm = 2 * (X_clipped - q_min+1e-4) / (q_max - q_min+1e-4) - 1\n",
    "    #X_norm = 2 * (X_clipped - X_clipped.min()+1e-4) / (X_clipped.max() - X_clipped.min()+1e-4) - 1\n",
    "    return X_norm,q_min,q_max\n",
    "def quantize(X, size):\n",
    "    device=X.device\n",
    "    half_width=(size-1)/2\n",
    "    offset=((size-1)%2)/2\n",
    "    X=X*half_width-offset\n",
    "    X_round=torch.round(X)\n",
    "    X_ste=(X_round-X).detach()+X\n",
    "    X_ste=(X_ste+offset)/half_width\n",
    "    #X_scaled=X*half_width-offset #modified on 11.3\n",
    "    #X_round=torch.round(X_scaled) #modified on 11.3\n",
    "    #X_round=(X_round+offset)/half_width #modified on 11.3\n",
    "    #X_ste=(X_round-X).detach()+X #modified on 11.3\n",
    "    indices=torch.round(X_ste*half_width+half_width)\n",
    "    return X_ste, indices.detach().int()\n",
    "    \n",
    "\n",
    "class FSQ(nn.Module):\n",
    "    def __init__(self, token_dim, code_dim, discrete_size=4):\n",
    "        super(FSQ, self).__init__()\n",
    "        assert discrete_size == 4, \"2-bit packing requires discrete_size=4\"\n",
    "\n",
    "        self.token_dim = token_dim\n",
    "        self.code_dim = code_dim\n",
    "        self.discrete_size = discrete_size\n",
    "\n",
    "        self.loss = CosineLoss()\n",
    "        self.in_proj = nn.Linear(token_dim, code_dim)\n",
    "        self.out_proj = nn.Linear(code_dim, token_dim)\n",
    "\n",
    "        self.levels = torch.linspace(-1, 1, steps=discrete_size)\n",
    "\n",
    "    # =========================\n",
    "    # Client-side\n",
    "    # =========================\n",
    "    def compress(self, x):\n",
    "        \"\"\"\n",
    "        x: [B, S, token_dim]\n",
    "        \"\"\"\n",
    "        x_shape = x.shape\n",
    "        x = self.in_proj(x)\n",
    "        x, q_min, q_max = robust_minmax(x)\n",
    "        flattened_x = x.view(-1, x.shape[-1])   # [B*S, H]\n",
    "        flattened_x_q, indices = quantize(\n",
    "            flattened_x, self.discrete_size\n",
    "        )                                       # indices ∈ {0,1,2,3}\n",
    "        target = torch.ones(flattened_x_q.shape[0], device=x.device)\n",
    "        L_comm = self.loss(flattened_x, flattened_x_q.detach(), target)\n",
    "        indices_uint8 = indices.to(torch.uint8)\n",
    "        packed,q_shape, pad = pack_2bit_tensor(indices_uint8)\n",
    "\n",
    "        payload = {\n",
    "            \"packed_indices\": packed,   # torch.uint8\n",
    "            \"pad\": pad,\n",
    "            \"q_shape\":q_shape\n",
    "        }\n",
    "\n",
    "        aux = {\n",
    "            \"embedding_shape\": x_shape,\n",
    "        }\n",
    "\n",
    "        return payload, aux, L_comm\n",
    "\n",
    "    # =========================\n",
    "    # Server-side\n",
    "    # =========================\n",
    "    def decompress(self, payload, aux):\n",
    "        packed = payload[\"packed_indices\"]\n",
    "        pad = payload[\"pad\"]\n",
    "        q_shape = payload[\"q_shape\"]\n",
    "        x_shape = aux[\"embedding_shape\"]\n",
    "\n",
    "        indices = unpack_2bit_tensor(packed,q_shape, pad)   # float tensor\n",
    "        indices = indices.view(-1, self.code_dim)\n",
    "\n",
    "        half_len = (self.discrete_size - 1) / 2\n",
    "        flattened_x_q = (indices - half_len) / half_len\n",
    "        output = self.out_proj(flattened_x_q)\n",
    "\n",
    "        return output.view(x_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9c4ea6c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (40x1280 and 128x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m s\u001b[38;5;241m=\u001b[39mFSQ(\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      2\u001b[0m x\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m1280\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m payload, aux, _\u001b[38;5;241m=\u001b[39m\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m e\u001b[38;5;241m=\u001b[39ms\u001b[38;5;241m.\u001b[39mdecompress(payload, aux)\n\u001b[1;32m      5\u001b[0m e\u001b[38;5;241m.\u001b[39mshape\n",
      "Cell \u001b[0;32mIn[98], line 116\u001b[0m, in \u001b[0;36mFSQ.compress\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03mx: [B, S, token_dim]\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    115\u001b[0m x_shape \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 116\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m x, q_min, q_max \u001b[38;5;241m=\u001b[39m robust_minmax(x)\n\u001b[1;32m    118\u001b[0m flattened_x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])   \u001b[38;5;66;03m# [B*S, H]\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/tinyllava_factory/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/tinyllava_factory/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (40x1280 and 128x128)"
     ]
    }
   ],
   "source": [
    "s=FSQ(128,128,4)\n",
    "\n",
    "payload, aux, _=s.compress(x)\n",
    "e=s.decompress(payload, aux)\n",
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5fee6f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class NFNDoubleQuantizer_split(nn.Module):\n",
    "    def __init__(self, bits=4, block_size=64, use_double_quant=True):\n",
    "        super().__init__()\n",
    "        self.bits = bits\n",
    "        self.block_size = block_size\n",
    "        self.use_double_quant = use_double_quant\n",
    "        self.table=generate_nf_table(bits)\n",
    "\n",
    "    def compress(self, x):\n",
    "        original_shape=x.shape\n",
    "        x=x.view(-1,x.shape[2])\n",
    "        x_shape = x.shape\n",
    "        x = x.view(x_shape[0], x_shape[1] // self.block_size, self.block_size)\n",
    "        x_min = x.min(dim=2).values.unsqueeze(-1)\n",
    "        x_max = x.max(dim=2).values.unsqueeze(-1)\n",
    "        scales = (x_max - x_min).squeeze(-1)\n",
    "\n",
    "        x_norm = 2 * (x - x_min) / (x_max - x_min + 1e-8) - 1\n",
    "        dist = torch.abs(x_norm.unsqueeze(-1) - self.table.to(x.device))\n",
    "        q_idx = torch.argmin(dist, dim=-1).to(torch.uint8)\n",
    "\n",
    "        if self.use_double_quant:\n",
    "            s_min = scales.min(dim=-1).values.unsqueeze(-1)\n",
    "            s_max = scales.max(dim=-1).values.unsqueeze(-1)\n",
    "            scales_q = ((scales - s_min) / (s_max - s_min + 1e-8) * 255).round().to(torch.uint8)\n",
    "        else:\n",
    "            scales_q, s_min, s_max = None, scales, None\n",
    "    \n",
    "        packed,q_shape, pad = pack_2bit_tensor(q_idx)\n",
    "        payload = {\n",
    "            \"packed_indices\": packed,   # torch.uint8\n",
    "            \"pad\": pad,\n",
    "            \"q_shape\":q_shape\n",
    "        }\n",
    "\n",
    "        aux = {\n",
    "            \"scales_q\": scales_q,\n",
    "            \"s_min\": s_min,\n",
    "            \"s_max\": s_max,\n",
    "            \"mins\": x_min,\n",
    "            \"x_shape\": x_shape,\n",
    "            \"original_shape\":original_shape\n",
    "        }\n",
    "\n",
    "        return payload, aux, 0\n",
    "    def decompress(self, payload, aux):\n",
    "        packed = payload[\"packed_indices\"]\n",
    "        pad = payload[\"pad\"]\n",
    "        q_shape = payload[\"q_shape\"]\n",
    "        q_idx=unpack_2bit_tensor(packed,q_shape,pad)\n",
    "        scales_q = aux[\"scales_q\"]\n",
    "        s_min = aux[\"s_min\"]\n",
    "        s_max = aux[\"s_max\"]\n",
    "        mins = aux[\"mins\"]\n",
    "        x_shape = aux[\"x_shape\"]\n",
    "        original_shape=aux[\"original_shape\"]\n",
    "\n",
    "        if scales_q is not None:\n",
    "            scales = s_min + (scales_q.float() / 255) * (s_max - s_min)\n",
    "        else:\n",
    "            scales = s_min\n",
    "\n",
    "        scales = scales.unsqueeze(-1)\n",
    "\n",
    "        w_block = self.table[q_idx.long()].to(dtype=torch.float32, device=scales.device)\n",
    "        w_block = (w_block + 1) / 2 * scales + mins\n",
    "        flatten_x=w_block.view(x_shape)\n",
    "        return flatten_x.view(original_shape)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b276dbc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 1280])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "s=NFNDoubleQuantizer_split()\n",
    "x=torch.randn(4,10,1280)\n",
    "payload, aux, _=s.compress(x)\n",
    "e=s.decompress(payload, aux)\n",
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7dbdf6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([139,  92,  61,  ..., 253, 216, 118], dtype=torch.uint8),\n",
       " torch.Size([40, 20, 64]),\n",
       " 0)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70d644f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinyllava",
   "language": "python",
   "name": "tinyllava"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
