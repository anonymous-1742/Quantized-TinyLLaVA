{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4949a1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gjiajun/.conda/envs/tinyllava_factory/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/gjiajun/.conda/envs/tinyllava_factory/lib/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/gjiajun/.conda/envs/tinyllava_factory/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gjiajun/.conda/envs/tinyllava_factory/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n",
      "[2025-06-26 16:13:46,305] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from packaging import version\n",
    "import pathlib\n",
    "\n",
    "import tokenizers\n",
    "import transformers\n",
    "\n",
    "\n",
    "from tinyllava.train.tinyllava_trainer import LLaVATrainer\n",
    "from tinyllava.training_recipe import TrainingRecipeFactory\n",
    "from tinyllava.utils import *\n",
    "from tinyllava.model import *\n",
    "from tinyllava.data.dataset import make_supervised_data_module\n",
    "\n",
    "IS_TOKENIZER_GREATER_THAN_0_14 = version.parse(tokenizers.__version__) >= version.parse('0.14')\n",
    "\n",
    "\n",
    "def load_settings(model_arguments, data_arguments, training_arguments):\n",
    "    model_arguments.tune_type_connector = training_arguments.tune_type_connector\n",
    "    model_arguments.tune_type_llm = training_arguments.tune_type_llm\n",
    "    model_arguments.tune_type_vision_tower = training_arguments.tune_type_vision_tower\n",
    "    model_arguments.image_aspect_ratio = data_arguments.image_aspect_ratio\n",
    "\n",
    "    model_args = {}\n",
    "    model_args['llm'] = _load_llm_settings(model_arguments)\n",
    "    model_args['vision_tower'] = _load_vision_settings(model_arguments)\n",
    "    model_args['connector'] = _load_connector_settings(model_arguments) \n",
    "    return model_args\n",
    "\n",
    "def _load_llm_settings(model_arguments):\n",
    "    llm_args = {}\n",
    "    llm_args['model_name_or_path'] = model_arguments.model_name_or_path\n",
    "    llm_args['cache_dir'] = model_arguments.cache_dir\n",
    "    llm_args['attn_implementation'] = model_arguments.attn_implementation # flash_attention_2 only supports torch.float16 and torch.bfloat16 dtypes\n",
    "    return llm_args\n",
    "\n",
    "def _load_vision_settings(model_arguments):\n",
    "    vision_args = {}\n",
    "    vision_args['model_name_or_path'] = model_arguments.vision_tower.split(':')[-1]\n",
    "    if model_arguments.vision_tower2 != '':\n",
    "        vision_args['model_name_or_path2'] = model_arguments.vision_tower2.split(':')[-1]\n",
    "    return vision_args\n",
    "\n",
    "def _load_connector_settings(model_arguments):\n",
    "    connector_args = {}\n",
    "    connector_args['connector_type'] = model_arguments.connector_type\n",
    "    return connector_args\n",
    "\n",
    "\n",
    "def train():\n",
    "    \n",
    "    # load argument\n",
    "    parser = transformers.HfArgumentParser(\n",
    "        (ModelArguments, DataArguments, TrainingArguments))\n",
    "    model_arguments, data_arguments, training_arguments = parser.parse_args_into_dataclasses()\n",
    "    \n",
    "    logger_setting(getattr(training_arguments, 'output_dir', None))\n",
    "\n",
    "    training_recipe = TrainingRecipeFactory(training_arguments.training_recipe)(training_arguments) \n",
    "    # model_args contain arguements for huggingface model .from_pretrained function\n",
    "    model_args = load_settings(model_arguments, data_arguments, training_arguments)\n",
    "    model_args = training_recipe.add_args(model_args)\n",
    "    model_config = TinyLlavaConfig()\n",
    "    model_config.load_from_config(model_arguments)\n",
    "    model = TinyLlavaForConditionalGeneration(model_config)\n",
    "    # load pretrained checkpoint\n",
    "    if training_arguments.pretrained_model_path is not None:\n",
    "        model = training_recipe.load(model, model_args)\n",
    "    else:\n",
    "        model.load_llm(**model_args['llm'])\n",
    "        model.load_vision_tower(**model_args['vision_tower'])\n",
    "        model.load_connector(**model_args['connector'])\n",
    "\n",
    "    model = training_recipe(model)\n",
    "    model.config.use_cache = False\n",
    "    model.config.image_aspect_ratio = data_arguments.image_aspect_ratio\n",
    "    tokenizer = model.tokenizer\n",
    "    data_arguments.image_processor = model.vision_tower._image_processor\n",
    "    data_arguments.is_multimodal = True\n",
    "    data_module = make_supervised_data_module(tokenizer=tokenizer,\n",
    "                                              data_args=data_arguments)\n",
    "    log_trainable_params(model)  # not work well with zero3\n",
    "    trainer = LLaVATrainer(model=model, #does not require model.to(device), huggingface/deepspeed does it for you?\n",
    "                           tokenizer=tokenizer,\n",
    "                           args=training_arguments,\n",
    "                           **data_module)\n",
    "    \n",
    "    trainer.train()\n",
    "    \n",
    "    training_recipe.save(model, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cdcb026",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--cache_dir CACHE_DIR]\n",
      "                             [--model_name_or_path MODEL_NAME_OR_PATH]\n",
      "                             [--tokenizer_name_or_path TOKENIZER_NAME_OR_PATH]\n",
      "                             [--attn_implementation ATTN_IMPLEMENTATION]\n",
      "                             [--vision_tower VISION_TOWER]\n",
      "                             [--vision_tower2 VISION_TOWER2]\n",
      "                             [--connector_type CONNECTOR_TYPE]\n",
      "                             [--mm_vision_select_layer MM_VISION_SELECT_LAYER]\n",
      "                             [--mm_patch_merge_type MM_PATCH_MERGE_TYPE]\n",
      "                             [--mm_vision_select_feature MM_VISION_SELECT_FEATURE]\n",
      "                             [--resampler_hidden_size RESAMPLER_HIDDEN_SIZE]\n",
      "                             [--num_queries NUM_QUERIES]\n",
      "                             [--num_resampler_layers NUM_RESAMPLER_LAYERS]\n",
      "                             [--model_max_length MODEL_MAX_LENGTH]\n",
      "                             [--tokenizer_use_fast [TOKENIZER_USE_FAST]]\n",
      "                             [--tokenizer_padding_side TOKENIZER_PADDING_SIDE]\n",
      "                             [--data_path DATA_PATH]\n",
      "                             [--lazy_preprocess [LAZY_PREPROCESS]]\n",
      "                             [--is_multimodal [IS_MULTIMODAL]]\n",
      "                             [--no_is_multimodal]\n",
      "                             [--image_folder IMAGE_FOLDER]\n",
      "                             [--image_aspect_ratio IMAGE_ASPECT_RATIO]\n",
      "                             [--conv_version CONV_VERSION] --output_dir\n",
      "                             OUTPUT_DIR\n",
      "                             [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]\n",
      "                             [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]\n",
      "                             [--do_predict [DO_PREDICT]]\n",
      "                             [--evaluation_strategy {no,steps,epoch}]\n",
      "                             [--prediction_loss_only [PREDICTION_LOSS_ONLY]]\n",
      "                             [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]\n",
      "                             [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]\n",
      "                             [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]\n",
      "                             [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]\n",
      "                             [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
      "                             [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]\n",
      "                             [--eval_delay EVAL_DELAY]\n",
      "                             [--learning_rate LEARNING_RATE]\n",
      "                             [--weight_decay WEIGHT_DECAY]\n",
      "                             [--adam_beta1 ADAM_BETA1]\n",
      "                             [--adam_beta2 ADAM_BETA2]\n",
      "                             [--adam_epsilon ADAM_EPSILON]\n",
      "                             [--max_grad_norm MAX_GRAD_NORM]\n",
      "                             [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
      "                             [--max_steps MAX_STEPS]\n",
      "                             [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup,inverse_sqrt,reduce_lr_on_plateau,cosine_with_min_lr}]\n",
      "                             [--lr_scheduler_kwargs LR_SCHEDULER_KWARGS]\n",
      "                             [--warmup_ratio WARMUP_RATIO]\n",
      "                             [--warmup_steps WARMUP_STEPS]\n",
      "                             [--log_level {detail,debug,info,warning,error,critical,passive}]\n",
      "                             [--log_level_replica {detail,debug,info,warning,error,critical,passive}]\n",
      "                             [--log_on_each_node [LOG_ON_EACH_NODE]]\n",
      "                             [--no_log_on_each_node]\n",
      "                             [--logging_dir LOGGING_DIR]\n",
      "                             [--logging_strategy {no,steps,epoch}]\n",
      "                             [--logging_first_step [LOGGING_FIRST_STEP]]\n",
      "                             [--logging_steps LOGGING_STEPS]\n",
      "                             [--logging_nan_inf_filter [LOGGING_NAN_INF_FILTER]]\n",
      "                             [--no_logging_nan_inf_filter]\n",
      "                             [--save_strategy {no,steps,epoch}]\n",
      "                             [--save_steps SAVE_STEPS]\n",
      "                             [--save_total_limit SAVE_TOTAL_LIMIT]\n",
      "                             [--save_safetensors [SAVE_SAFETENSORS]]\n",
      "                             [--no_save_safetensors]\n",
      "                             [--save_on_each_node [SAVE_ON_EACH_NODE]]\n",
      "                             [--save_only_model [SAVE_ONLY_MODEL]]\n",
      "                             [--no_cuda [NO_CUDA]] [--use_cpu [USE_CPU]]\n",
      "                             [--use_mps_device [USE_MPS_DEVICE]] [--seed SEED]\n",
      "                             [--data_seed DATA_SEED]\n",
      "                             [--jit_mode_eval [JIT_MODE_EVAL]]\n",
      "                             [--use_ipex [USE_IPEX]] [--bf16 [BF16]]\n",
      "                             [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]\n",
      "                             [--half_precision_backend {auto,apex,cpu_amp}]\n",
      "                             [--bf16_full_eval [BF16_FULL_EVAL]]\n",
      "                             [--fp16_full_eval [FP16_FULL_EVAL]] [--tf32 TF32]\n",
      "                             [--local_rank LOCAL_RANK]\n",
      "                             [--ddp_backend {nccl,gloo,mpi,ccl,hccl,cncl}]\n",
      "                             [--tpu_num_cores TPU_NUM_CORES]\n",
      "                             [--tpu_metrics_debug [TPU_METRICS_DEBUG]]\n",
      "                             [--debug DEBUG [DEBUG ...]]\n",
      "                             [--dataloader_drop_last [DATALOADER_DROP_LAST]]\n",
      "                             [--eval_steps EVAL_STEPS]\n",
      "                             [--dataloader_num_workers DATALOADER_NUM_WORKERS]\n",
      "                             [--dataloader_prefetch_factor DATALOADER_PREFETCH_FACTOR]\n",
      "                             [--past_index PAST_INDEX] [--run_name RUN_NAME]\n",
      "                             [--disable_tqdm DISABLE_TQDM]\n",
      "                             [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]\n",
      "                             [--label_names LABEL_NAMES [LABEL_NAMES ...]]\n",
      "                             [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]\n",
      "                             [--metric_for_best_model METRIC_FOR_BEST_MODEL]\n",
      "                             [--greater_is_better GREATER_IS_BETTER]\n",
      "                             [--ignore_data_skip [IGNORE_DATA_SKIP]]\n",
      "                             [--fsdp FSDP]\n",
      "                             [--fsdp_min_num_params FSDP_MIN_NUM_PARAMS]\n",
      "                             [--fsdp_config FSDP_CONFIG]\n",
      "                             [--fsdp_transformer_layer_cls_to_wrap FSDP_TRANSFORMER_LAYER_CLS_TO_WRAP]\n",
      "                             [--accelerator_config ACCELERATOR_CONFIG]\n",
      "                             [--deepspeed DEEPSPEED]\n",
      "                             [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]\n",
      "                             [--optim OPTIM] [--optim_args OPTIM_ARGS]\n",
      "                             [--adafactor [ADAFACTOR]]\n",
      "                             [--group_by_length [GROUP_BY_LENGTH]]\n",
      "                             [--length_column_name LENGTH_COLUMN_NAME]\n",
      "                             [--report_to REPORT_TO]\n",
      "                             [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]\n",
      "                             [--ddp_bucket_cap_mb DDP_BUCKET_CAP_MB]\n",
      "                             [--ddp_broadcast_buffers DDP_BROADCAST_BUFFERS]\n",
      "                             [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]\n",
      "                             [--no_dataloader_pin_memory]\n",
      "                             [--dataloader_persistent_workers [DATALOADER_PERSISTENT_WORKERS]]\n",
      "                             [--skip_memory_metrics [SKIP_MEMORY_METRICS]]\n",
      "                             [--no_skip_memory_metrics]\n",
      "                             [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]\n",
      "                             [--push_to_hub [PUSH_TO_HUB]]\n",
      "                             [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]\n",
      "                             [--hub_model_id HUB_MODEL_ID]\n",
      "                             [--hub_strategy {end,every_save,checkpoint,all_checkpoints}]\n",
      "                             [--hub_token HUB_TOKEN]\n",
      "                             [--hub_private_repo [HUB_PRIVATE_REPO]]\n",
      "                             [--hub_always_push [HUB_ALWAYS_PUSH]]\n",
      "                             [--gradient_checkpointing [GRADIENT_CHECKPOINTING]]\n",
      "                             [--gradient_checkpointing_kwargs GRADIENT_CHECKPOINTING_KWARGS]\n",
      "                             [--include_inputs_for_metrics [INCLUDE_INPUTS_FOR_METRICS]]\n",
      "                             [--eval_do_concat_batches [EVAL_DO_CONCAT_BATCHES]]\n",
      "                             [--no_eval_do_concat_batches]\n",
      "                             [--fp16_backend {auto,apex,cpu_amp}]\n",
      "                             [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]\n",
      "                             [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]\n",
      "                             [--push_to_hub_token PUSH_TO_HUB_TOKEN]\n",
      "                             [--mp_parameters MP_PARAMETERS]\n",
      "                             [--auto_find_batch_size [AUTO_FIND_BATCH_SIZE]]\n",
      "                             [--full_determinism [FULL_DETERMINISM]]\n",
      "                             [--torchdynamo TORCHDYNAMO]\n",
      "                             [--ray_scope RAY_SCOPE]\n",
      "                             [--ddp_timeout DDP_TIMEOUT]\n",
      "                             [--torch_compile [TORCH_COMPILE]]\n",
      "                             [--torch_compile_backend TORCH_COMPILE_BACKEND]\n",
      "                             [--torch_compile_mode TORCH_COMPILE_MODE]\n",
      "                             [--dispatch_batches DISPATCH_BATCHES]\n",
      "                             [--split_batches SPLIT_BATCHES]\n",
      "                             [--include_tokens_per_second [INCLUDE_TOKENS_PER_SECOND]]\n",
      "                             [--include_num_input_tokens_seen [INCLUDE_NUM_INPUT_TOKENS_SEEN]]\n",
      "                             [--neftune_noise_alpha NEFTUNE_NOISE_ALPHA]\n",
      "                             [--optim_target_modules OPTIM_TARGET_MODULES]\n",
      "                             [--training_recipe TRAINING_RECIPE]\n",
      "                             [--tune_type_llm TUNE_TYPE_LLM]\n",
      "                             [--tune_type_vision_tower TUNE_TYPE_VISION_TOWER]\n",
      "                             [--tune_vision_tower_from_layer TUNE_VISION_TOWER_FROM_LAYER]\n",
      "                             [--tune_type_connector TUNE_TYPE_CONNECTOR]\n",
      "                             [--tune_embed_tokens TUNE_EMBED_TOKENS]\n",
      "                             [--double_quant [DOUBLE_QUANT]]\n",
      "                             [--no_double_quant] [--quant_type QUANT_TYPE]\n",
      "                             [--bits BITS] [--lora_r LORA_R]\n",
      "                             [--lora_alpha LORA_ALPHA]\n",
      "                             [--lora_dropout LORA_DROPOUT]\n",
      "                             [--lora_weight_path LORA_WEIGHT_PATH]\n",
      "                             [--lora_bias LORA_BIAS]\n",
      "                             [--mm_projector_lr MM_PROJECTOR_LR]\n",
      "                             [--group_by_modality_length [GROUP_BY_MODALITY_LENGTH]]\n",
      "                             [--vision_tower_lr VISION_TOWER_LR]\n",
      "                             [--pretrained_model_path PRETRAINED_MODEL_PATH]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --output_dir\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "parser = transformers.HfArgumentParser(\n",
    "        (ModelArguments, DataArguments, TrainingArguments))\n",
    "model_arguments, data_arguments, training_arguments = parser.parse_args_into_dataclasses()\n",
    "    \n",
    "logger_setting(getattr(training_arguments, 'output_dir', None))\n",
    "\n",
    "training_recipe = TrainingRecipeFactory(training_arguments.training_recipe)(training_arguments) \n",
    "    # model_args contain arguements for huggingface model .from_pretrained function\n",
    "model_args = load_settings(model_arguments, data_arguments, training_arguments)\n",
    "model_args = training_recipe.add_args(model_args)\n",
    "model_config = TinyLlavaConfig()\n",
    "model_config.load_from_config(model_arguments)\n",
    "model = TinyLlavaForConditionalGeneration(model_config)\n",
    "    # load pretrained checkpoint\n",
    "if training_arguments.pretrained_model_path is not None:\n",
    "    model = training_recipe.load(model, model_args)\n",
    "else:\n",
    "    model.load_llm(**model_args['llm'])\n",
    "    model.load_vision_tower(**model_args['vision_tower'])\n",
    "    model.load_connector(**model_args['connector'])\n",
    "\n",
    "model = training_recipe(model)\n",
    "model.config.use_cache = False\n",
    "model.config.image_aspect_ratio = data_arguments.image_aspect_ratio\n",
    "tokenizer = model.tokenizer\n",
    "data_arguments.image_processor = model.vision_tower._image_processor\n",
    "data_arguments.is_multimodal = True\n",
    "data_module = make_supervised_data_module(tokenizer=tokenizer,\n",
    "                                              data_args=data_arguments)\n",
    "log_trainable_params(model)  # not work well with zero3\n",
    "trainer = LLaVATrainer(model=model, #does not require model.to(device), huggingface/deepspeed does it for you?\n",
    "                           tokenizer=tokenizer,\n",
    "                           args=training_arguments,\n",
    "                           **data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43652aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--cache_dir CACHE_DIR]\n",
      "                             [--model_name_or_path MODEL_NAME_OR_PATH]\n",
      "                             [--tokenizer_name_or_path TOKENIZER_NAME_OR_PATH]\n",
      "                             [--attn_implementation ATTN_IMPLEMENTATION]\n",
      "                             [--vision_tower VISION_TOWER]\n",
      "                             [--vision_tower2 VISION_TOWER2]\n",
      "                             [--connector_type CONNECTOR_TYPE]\n",
      "                             [--mm_vision_select_layer MM_VISION_SELECT_LAYER]\n",
      "                             [--mm_patch_merge_type MM_PATCH_MERGE_TYPE]\n",
      "                             [--mm_vision_select_feature MM_VISION_SELECT_FEATURE]\n",
      "                             [--resampler_hidden_size RESAMPLER_HIDDEN_SIZE]\n",
      "                             [--num_queries NUM_QUERIES]\n",
      "                             [--num_resampler_layers NUM_RESAMPLER_LAYERS]\n",
      "                             [--model_max_length MODEL_MAX_LENGTH]\n",
      "                             [--tokenizer_use_fast [TOKENIZER_USE_FAST]]\n",
      "                             [--tokenizer_padding_side TOKENIZER_PADDING_SIDE]\n",
      "                             [--data_path DATA_PATH]\n",
      "                             [--lazy_preprocess [LAZY_PREPROCESS]]\n",
      "                             [--is_multimodal [IS_MULTIMODAL]]\n",
      "                             [--no_is_multimodal]\n",
      "                             [--image_folder IMAGE_FOLDER]\n",
      "                             [--image_aspect_ratio IMAGE_ASPECT_RATIO]\n",
      "                             [--conv_version CONV_VERSION] --output_dir\n",
      "                             OUTPUT_DIR\n",
      "                             [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]\n",
      "                             [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]\n",
      "                             [--do_predict [DO_PREDICT]]\n",
      "                             [--evaluation_strategy {no,steps,epoch}]\n",
      "                             [--prediction_loss_only [PREDICTION_LOSS_ONLY]]\n",
      "                             [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]\n",
      "                             [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]\n",
      "                             [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]\n",
      "                             [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]\n",
      "                             [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
      "                             [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]\n",
      "                             [--eval_delay EVAL_DELAY]\n",
      "                             [--learning_rate LEARNING_RATE]\n",
      "                             [--weight_decay WEIGHT_DECAY]\n",
      "                             [--adam_beta1 ADAM_BETA1]\n",
      "                             [--adam_beta2 ADAM_BETA2]\n",
      "                             [--adam_epsilon ADAM_EPSILON]\n",
      "                             [--max_grad_norm MAX_GRAD_NORM]\n",
      "                             [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
      "                             [--max_steps MAX_STEPS]\n",
      "                             [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup,inverse_sqrt,reduce_lr_on_plateau,cosine_with_min_lr}]\n",
      "                             [--lr_scheduler_kwargs LR_SCHEDULER_KWARGS]\n",
      "                             [--warmup_ratio WARMUP_RATIO]\n",
      "                             [--warmup_steps WARMUP_STEPS]\n",
      "                             [--log_level {detail,debug,info,warning,error,critical,passive}]\n",
      "                             [--log_level_replica {detail,debug,info,warning,error,critical,passive}]\n",
      "                             [--log_on_each_node [LOG_ON_EACH_NODE]]\n",
      "                             [--no_log_on_each_node]\n",
      "                             [--logging_dir LOGGING_DIR]\n",
      "                             [--logging_strategy {no,steps,epoch}]\n",
      "                             [--logging_first_step [LOGGING_FIRST_STEP]]\n",
      "                             [--logging_steps LOGGING_STEPS]\n",
      "                             [--logging_nan_inf_filter [LOGGING_NAN_INF_FILTER]]\n",
      "                             [--no_logging_nan_inf_filter]\n",
      "                             [--save_strategy {no,steps,epoch}]\n",
      "                             [--save_steps SAVE_STEPS]\n",
      "                             [--save_total_limit SAVE_TOTAL_LIMIT]\n",
      "                             [--save_safetensors [SAVE_SAFETENSORS]]\n",
      "                             [--no_save_safetensors]\n",
      "                             [--save_on_each_node [SAVE_ON_EACH_NODE]]\n",
      "                             [--save_only_model [SAVE_ONLY_MODEL]]\n",
      "                             [--no_cuda [NO_CUDA]] [--use_cpu [USE_CPU]]\n",
      "                             [--use_mps_device [USE_MPS_DEVICE]] [--seed SEED]\n",
      "                             [--data_seed DATA_SEED]\n",
      "                             [--jit_mode_eval [JIT_MODE_EVAL]]\n",
      "                             [--use_ipex [USE_IPEX]] [--bf16 [BF16]]\n",
      "                             [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]\n",
      "                             [--half_precision_backend {auto,apex,cpu_amp}]\n",
      "                             [--bf16_full_eval [BF16_FULL_EVAL]]\n",
      "                             [--fp16_full_eval [FP16_FULL_EVAL]] [--tf32 TF32]\n",
      "                             [--local_rank LOCAL_RANK]\n",
      "                             [--ddp_backend {nccl,gloo,mpi,ccl,hccl,cncl}]\n",
      "                             [--tpu_num_cores TPU_NUM_CORES]\n",
      "                             [--tpu_metrics_debug [TPU_METRICS_DEBUG]]\n",
      "                             [--debug DEBUG [DEBUG ...]]\n",
      "                             [--dataloader_drop_last [DATALOADER_DROP_LAST]]\n",
      "                             [--eval_steps EVAL_STEPS]\n",
      "                             [--dataloader_num_workers DATALOADER_NUM_WORKERS]\n",
      "                             [--dataloader_prefetch_factor DATALOADER_PREFETCH_FACTOR]\n",
      "                             [--past_index PAST_INDEX] [--run_name RUN_NAME]\n",
      "                             [--disable_tqdm DISABLE_TQDM]\n",
      "                             [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]\n",
      "                             [--label_names LABEL_NAMES [LABEL_NAMES ...]]\n",
      "                             [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]\n",
      "                             [--metric_for_best_model METRIC_FOR_BEST_MODEL]\n",
      "                             [--greater_is_better GREATER_IS_BETTER]\n",
      "                             [--ignore_data_skip [IGNORE_DATA_SKIP]]\n",
      "                             [--fsdp FSDP]\n",
      "                             [--fsdp_min_num_params FSDP_MIN_NUM_PARAMS]\n",
      "                             [--fsdp_config FSDP_CONFIG]\n",
      "                             [--fsdp_transformer_layer_cls_to_wrap FSDP_TRANSFORMER_LAYER_CLS_TO_WRAP]\n",
      "                             [--accelerator_config ACCELERATOR_CONFIG]\n",
      "                             [--deepspeed DEEPSPEED]\n",
      "                             [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]\n",
      "                             [--optim OPTIM] [--optim_args OPTIM_ARGS]\n",
      "                             [--adafactor [ADAFACTOR]]\n",
      "                             [--group_by_length [GROUP_BY_LENGTH]]\n",
      "                             [--length_column_name LENGTH_COLUMN_NAME]\n",
      "                             [--report_to REPORT_TO]\n",
      "                             [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]\n",
      "                             [--ddp_bucket_cap_mb DDP_BUCKET_CAP_MB]\n",
      "                             [--ddp_broadcast_buffers DDP_BROADCAST_BUFFERS]\n",
      "                             [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]\n",
      "                             [--no_dataloader_pin_memory]\n",
      "                             [--dataloader_persistent_workers [DATALOADER_PERSISTENT_WORKERS]]\n",
      "                             [--skip_memory_metrics [SKIP_MEMORY_METRICS]]\n",
      "                             [--no_skip_memory_metrics]\n",
      "                             [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]\n",
      "                             [--push_to_hub [PUSH_TO_HUB]]\n",
      "                             [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]\n",
      "                             [--hub_model_id HUB_MODEL_ID]\n",
      "                             [--hub_strategy {end,every_save,checkpoint,all_checkpoints}]\n",
      "                             [--hub_token HUB_TOKEN]\n",
      "                             [--hub_private_repo [HUB_PRIVATE_REPO]]\n",
      "                             [--hub_always_push [HUB_ALWAYS_PUSH]]\n",
      "                             [--gradient_checkpointing [GRADIENT_CHECKPOINTING]]\n",
      "                             [--gradient_checkpointing_kwargs GRADIENT_CHECKPOINTING_KWARGS]\n",
      "                             [--include_inputs_for_metrics [INCLUDE_INPUTS_FOR_METRICS]]\n",
      "                             [--eval_do_concat_batches [EVAL_DO_CONCAT_BATCHES]]\n",
      "                             [--no_eval_do_concat_batches]\n",
      "                             [--fp16_backend {auto,apex,cpu_amp}]\n",
      "                             [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]\n",
      "                             [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]\n",
      "                             [--push_to_hub_token PUSH_TO_HUB_TOKEN]\n",
      "                             [--mp_parameters MP_PARAMETERS]\n",
      "                             [--auto_find_batch_size [AUTO_FIND_BATCH_SIZE]]\n",
      "                             [--full_determinism [FULL_DETERMINISM]]\n",
      "                             [--torchdynamo TORCHDYNAMO]\n",
      "                             [--ray_scope RAY_SCOPE]\n",
      "                             [--ddp_timeout DDP_TIMEOUT]\n",
      "                             [--torch_compile [TORCH_COMPILE]]\n",
      "                             [--torch_compile_backend TORCH_COMPILE_BACKEND]\n",
      "                             [--torch_compile_mode TORCH_COMPILE_MODE]\n",
      "                             [--dispatch_batches DISPATCH_BATCHES]\n",
      "                             [--split_batches SPLIT_BATCHES]\n",
      "                             [--include_tokens_per_second [INCLUDE_TOKENS_PER_SECOND]]\n",
      "                             [--include_num_input_tokens_seen [INCLUDE_NUM_INPUT_TOKENS_SEEN]]\n",
      "                             [--neftune_noise_alpha NEFTUNE_NOISE_ALPHA]\n",
      "                             [--optim_target_modules OPTIM_TARGET_MODULES]\n",
      "                             [--training_recipe TRAINING_RECIPE]\n",
      "                             [--tune_type_llm TUNE_TYPE_LLM]\n",
      "                             [--tune_type_vision_tower TUNE_TYPE_VISION_TOWER]\n",
      "                             [--tune_vision_tower_from_layer TUNE_VISION_TOWER_FROM_LAYER]\n",
      "                             [--tune_type_connector TUNE_TYPE_CONNECTOR]\n",
      "                             [--tune_embed_tokens TUNE_EMBED_TOKENS]\n",
      "                             [--double_quant [DOUBLE_QUANT]]\n",
      "                             [--no_double_quant] [--quant_type QUANT_TYPE]\n",
      "                             [--bits BITS] [--lora_r LORA_R]\n",
      "                             [--lora_alpha LORA_ALPHA]\n",
      "                             [--lora_dropout LORA_DROPOUT]\n",
      "                             [--lora_weight_path LORA_WEIGHT_PATH]\n",
      "                             [--lora_bias LORA_BIAS]\n",
      "                             [--mm_projector_lr MM_PROJECTOR_LR]\n",
      "                             [--group_by_modality_length [GROUP_BY_MODALITY_LENGTH]]\n",
      "                             [--vision_tower_lr VISION_TOWER_LR]\n",
      "                             [--pretrained_model_path PRETRAINED_MODEL_PATH]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --output_dir\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "model_arguments, data_arguments, training_arguments = parser.parse_args_into_dataclasses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c4816b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinyllava",
   "language": "python",
   "name": "tinyllava_factory"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
