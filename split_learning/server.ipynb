{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac771988",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gjiajun/.conda/envs/tinyllava_factory/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-13 13:46:22,376] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from tinyllava.model.VQ.vq import FSQ_block,VQ_config\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import quantize as qt\n",
    "import socket\n",
    "import struct\n",
    "import pickle\n",
    "\n",
    "class Server(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.Linear2=nn.Sequential(nn.Linear(100,3),nn.Softmax())\n",
    "        config=VQ_config(token_dim=100,code_dim=100,discrete_size=4)\n",
    "        self.VQ=FSQ_block(config)\n",
    "        self.quantizer=self.VQ.quantizer\n",
    "    def forward(self,payload,aux,quantize=False):\n",
    "        if quantize:\n",
    "            x=self.quantizer.decompress(payload,aux)\n",
    "        x=self.Linear2(payload)\n",
    "        return(x)\n",
    "    \n",
    "class DummyDataset(Dataset):\n",
    "    def __init__(self, num_samples=200, seq_len=100, num_classes=3):\n",
    "        self.num_samples = num_samples\n",
    "        self.num_classes = num_classes\n",
    "        self.labels = torch.randint(0, num_classes, (num_samples,seq_len,))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.labels[idx] \n",
    "\n",
    "def send_tensor(sock, tensor: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Send a torch Tensor through a socket\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. detach + cpu\n",
    "        if isinstance(tensor, torch.Tensor):\n",
    "            tensor_cpu = tensor.detach().cpu()\n",
    "\n",
    "        # 2. serialize\n",
    "        data = pickle.dumps(tensor_cpu)\n",
    "        data_length = len(data)\n",
    "\n",
    "        print(f\"✓ Serialized tensor: {data_length} bytes\")\n",
    "\n",
    "        # 3. send length\n",
    "        sock.sendall(data_length.to_bytes(4, byteorder='big'))\n",
    "        print(f\"✓ Sent length: {data_length} bytes\")\n",
    "\n",
    "        # 4. send payload\n",
    "        sock.sendall(data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"✗ send_tensor error: {e}\")\n",
    "        raise\n",
    "        \n",
    "def receive_tensor(sock):\n",
    "    \"\"\"\n",
    "    Receive a torch Tensor from socket\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. receive length\n",
    "        length_bytes = sock.recv(4)\n",
    "        if not length_bytes:\n",
    "            return None\n",
    "\n",
    "        data_length = int.from_bytes(length_bytes, byteorder='big')\n",
    "        print(f\"✓ Expecting {data_length} bytes\")\n",
    "\n",
    "        # 2. receive payload\n",
    "        received_data = b''\n",
    "        while len(received_data) < data_length:\n",
    "            chunk = sock.recv(min(4096, data_length - len(received_data)))\n",
    "            if not chunk:\n",
    "                raise RuntimeError(\"Socket connection broken\")\n",
    "            received_data += chunk\n",
    "\n",
    "        print(f\"✓ Received {len(received_data)} bytes\")\n",
    "\n",
    "        # 3. deserialize\n",
    "        tensor = pickle.loads(received_data)\n",
    "        print(f\"✓ Deserialized tensor\")\n",
    "\n",
    "        return tensor\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"✗ receive_tensor error: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3c0910b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] waiting for forward connection...\n",
      "[INFO] forward connected\n",
      "[INFO] waiting for backward connection...\n",
      "[INFO] backward connected\n",
      "✓ Expecting 20456 bytes\n",
      "✓ Received 20456 bytes\n",
      "✓ Deserialized tensor\n",
      "[ERROR] exception at training step 0\n",
      "[INFO] shutting down server...\n",
      "[INFO] fwd_sock closed\n",
      "[INFO] bwd_sock closed\n",
      "[INFO] fwd_server closed\n",
      "[INFO] bwd_server closed\n",
      "[INFO] server shutdown complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gjiajun/.conda/envs/tinyllava_factory/lib/python3.10/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2591810/1203011396.py\", line 67, in <module>\n",
      "    loss = loss_fn(pred, target)\n",
      "  File \"/home/gjiajun/.conda/envs/tinyllava_factory/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/gjiajun/.conda/envs/tinyllava_factory/lib/python3.10/site-packages/torch/nn/modules/loss.py\", line 1174, in forward\n",
      "    return F.cross_entropy(input, target, weight=self.weight,\n",
      "  File \"/home/gjiajun/.conda/envs/tinyllava_factory/lib/python3.10/site-packages/torch/nn/functional.py\", line 3029, in cross_entropy\n",
      "    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n",
      "ValueError: Expected input batch_size (800) to match target batch_size (8).\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import traceback\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def safe_close(sock, name):\n",
    "    try:\n",
    "        if sock:\n",
    "            sock.close()\n",
    "            print(f\"[INFO] {name} closed\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] failed to close {name}: {e}\")\n",
    "\n",
    "fwd_server = bwd_server = fwd_sock = bwd_sock = None\n",
    "\n",
    "try:\n",
    "    model = Server()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    host = '0.0.0.0'\n",
    "    forward_port = 5001\n",
    "    backward_port = 5002\n",
    "\n",
    "    # ===== forward socket =====\n",
    "    fwd_server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    fwd_server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
    "    fwd_server.bind((host, forward_port))\n",
    "    fwd_server.listen(1)\n",
    "    print(\"[INFO] waiting for forward connection...\")\n",
    "    fwd_sock, _ = fwd_server.accept()\n",
    "    print(\"[INFO] forward connected\")\n",
    "\n",
    "    # ===== backward socket =====\n",
    "    bwd_server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    bwd_server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
    "    bwd_server.bind((host, backward_port))\n",
    "    bwd_server.listen(1)\n",
    "    print(\"[INFO] waiting for backward connection...\")\n",
    "    bwd_sock, _ = bwd_server.accept()\n",
    "    print(\"[INFO] backward connected\")\n",
    "\n",
    "    trainset = DummyDataset()\n",
    "    trainloader = DataLoader(trainset, batch_size=8)\n",
    "\n",
    "    quantize = True\n",
    "\n",
    "    for step, target in enumerate(trainloader):\n",
    "        try:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            data_pack = receive_tensor(fwd_sock)\n",
    "\n",
    "            if quantize:\n",
    "                packed_payload, pad, aux, pack_shape = data_pack\n",
    "                payload = qt.unpack_2bit_tensor(packed_payload, pad)\n",
    "                payload = payload.reshape(pack_shape)\n",
    "            else:\n",
    "                payload = data_pack\n",
    "                aux = None\n",
    "\n",
    "            payload = payload.to(next(model.parameters()).device)\n",
    "            payload.requires_grad_(True)\n",
    "\n",
    "            # ===== forward =====\n",
    "            pred = model(payload, aux, quantize)\n",
    "            loss = loss_fn(pred, target)\n",
    "            print(f\"[INFO][step {step}] loss = {loss.item():.4f}\")\n",
    "\n",
    "            # ===== backward =====\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # ===== send gradient =====\n",
    "            send_tensor(bwd_sock, payload.grad)\n",
    "\n",
    "        except Exception:\n",
    "            print(f\"[ERROR] exception at training step {step}\")\n",
    "            traceback.print_exc()\n",
    "            break\n",
    "\n",
    "except Exception:\n",
    "    print(\"[FATAL] server crashed during initialization\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "finally:\n",
    "    print(\"[INFO] shutting down server...\")\n",
    "    safe_close(fwd_sock, \"fwd_sock\")\n",
    "    safe_close(bwd_sock, \"bwd_sock\")\n",
    "    safe_close(fwd_server, \"fwd_server\")\n",
    "    safe_close(bwd_server, \"bwd_server\")\n",
    "    print(\"[INFO] server shutdown complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7540038",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwd_sock.close()\n",
    "bwd_sock.close()\n",
    "fwd_server.close()\n",
    "bwd_server.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1eabb3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([800, 100])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d28c866",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinyllava",
   "language": "python",
   "name": "tinyllava"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
