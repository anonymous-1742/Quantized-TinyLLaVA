{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac771988",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gjiajun/.conda/envs/tinyllava_factory/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-13 13:46:23,968] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from tinyllava.model.VQ.vq import FSQ_block,VQ_config\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import socket\n",
    "import struct\n",
    "import pickle\n",
    "import quantize as qt\n",
    "\n",
    "class Client(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.Linear1=nn.Sequential(nn.Linear(100,100),nn.ReLU())\n",
    "        config=VQ_config(token_dim=100,code_dim=100,discrete_size=4)\n",
    "        self.VQ=FSQ_block(config)\n",
    "        self.quantizer=self.VQ.quantizer\n",
    "        \n",
    "    def forward(self,x,quantize=False):\n",
    "        x=self.Linear1(x)\n",
    "        #x,L_comm=self.VQ(x,return_indice=True)\n",
    "        \n",
    "        if quantize:\n",
    "            payload,aux,vq_loss=self.quantizer.compress(x)\n",
    "            return(x,payload,aux,vq_loss)\n",
    "        else:\n",
    "            return(x,0,0,0)\n",
    "    \n",
    "class DummyDataset(Dataset):\n",
    "    def __init__(self, num_samples=200,seq_len=100 ,num_features=100, num_classes=3):\n",
    "        self.num_samples = num_samples\n",
    "        self.num_features = num_features\n",
    "        self.num_classes = num_classes\n",
    "        self.data = torch.randn(num_samples,seq_len, num_features)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "def send_tensor(sock, tensor: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Send a torch Tensor through a socket\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. detach + cpu\n",
    "        if isinstance(tensor, torch.Tensor):\n",
    "            tensor_cpu = tensor.detach().cpu\n",
    "        else:\n",
    "            tensor_cpu = tensor\n",
    "\n",
    "        # 2. serialize\n",
    "        data = pickle.dumps(tensor_cpu)\n",
    "        data_length = len(data)\n",
    "\n",
    "        print(f\"✓ Serialized tensor: {data_length} bytes\")\n",
    "\n",
    "        # 3. send length\n",
    "        sock.sendall(data_length.to_bytes(4, byteorder='big'))\n",
    "        print(f\"✓ Sent length: {data_length} bytes\")\n",
    "\n",
    "        # 4. send payload\n",
    "        sock.sendall(data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"✗ send_tensor error: {e}\")\n",
    "        raise\n",
    "    \n",
    "def receive_tensor(sock):\n",
    "    \"\"\"\n",
    "    Receive a torch Tensor from socket\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. receive length\n",
    "        length_bytes = sock.recv(4)\n",
    "        if not length_bytes:\n",
    "            return None\n",
    "\n",
    "        data_length = int.from_bytes(length_bytes, byteorder='big')\n",
    "        print(f\"✓ Expecting {data_length} bytes\")\n",
    "\n",
    "        # 2. receive payload\n",
    "        received_data = b''\n",
    "        while len(received_data) < data_length:\n",
    "            chunk = sock.recv(min(4096, data_length - len(received_data)))\n",
    "            if not chunk:\n",
    "                raise RuntimeError(\"Socket connection broken\")\n",
    "            received_data += chunk\n",
    "\n",
    "        print(f\"✓ Received {len(received_data)} bytes\")\n",
    "\n",
    "        # 3. deserialize\n",
    "        tensor = pickle.loads(received_data)\n",
    "        print(f\"✓ Deserialized tensor, shape={tensor.shape}\")\n",
    "\n",
    "        return tensor\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"✗ receive_tensor error: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3c0910b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] connected to server (forward)\n",
      "[INFO] connected to server (backward)\n",
      "✓ Serialized tensor: 20456 bytes\n",
      "✓ Sent length: 20456 bytes\n",
      "[ERROR] exception at client step 0\n",
      "[INFO] shutting down client...\n",
      "[INFO] fwd_sock closed\n",
      "[INFO] bwd_sock closed\n",
      "[INFO] client shutdown complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2591823/181257225.py\", line 59, in <module>\n",
      "    x.backward(grad)\n",
      "  File \"/home/gjiajun/.conda/envs/tinyllava_factory/lib/python3.10/site-packages/torch/_tensor.py\", line 487, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/gjiajun/.conda/envs/tinyllava_factory/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 193, in backward\n",
      "    grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)\n",
      "  File \"/home/gjiajun/.conda/envs/tinyllava_factory/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 88, in _make_grads\n",
      "    raise RuntimeError(\"grad can be implicitly created only for scalar outputs\")\n",
      "RuntimeError: grad can be implicitly created only for scalar outputs\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import traceback\n",
    "import torch\n",
    "\n",
    "def safe_close(sock, name):\n",
    "    try:\n",
    "        if sock:\n",
    "            sock.close()\n",
    "            print(f\"[INFO] {name} closed\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] failed to close {name}: {e}\")\n",
    "\n",
    "fwd_sock = bwd_sock = None\n",
    "\n",
    "try:\n",
    "    model = Client()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    server_host = 'localhost'\n",
    "    forward_port = 5001\n",
    "    backward_port = 5002\n",
    "\n",
    "    quantize = True\n",
    "\n",
    "    trainset = DummyDataset()\n",
    "    trainloader = DataLoader(trainset, batch_size=8)\n",
    "\n",
    "    # ===== connect =====\n",
    "    fwd_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    fwd_sock.connect((server_host, forward_port))\n",
    "    print(\"[INFO] connected to server (forward)\")\n",
    "\n",
    "    bwd_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    bwd_sock.connect((server_host, backward_port))\n",
    "    print(\"[INFO] connected to server (backward)\")\n",
    "\n",
    "    for step, data in enumerate(trainloader):\n",
    "        try:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # ===== forward =====\n",
    "            if quantize:\n",
    "                x, payload, aux, vq_loss = model(data, quantize)\n",
    "                packed_payload, pad = qt.pack_2bit_tensor(payload.to(torch.uint8))\n",
    "                pack_shape = payload.shape\n",
    "                data_pack = packed_payload, pad, aux, pack_shape\n",
    "            else:\n",
    "                x, _ = model(data, quantize)\n",
    "                data_pack = x\n",
    "\n",
    "            send_tensor(fwd_sock, data_pack)\n",
    "\n",
    "            x.requires_grad_(True)\n",
    "\n",
    "            # ===== receive gradient =====\n",
    "            grad = receive_tensor(bwd_sock)\n",
    "\n",
    "            # ===== backward =====\n",
    "            x.backward(grad)\n",
    "            optimizer.step()\n",
    "\n",
    "            print(f\"[INFO][step {step}] client step done\")\n",
    "\n",
    "        except Exception:\n",
    "            print(f\"[ERROR] exception at client step {step}\")\n",
    "            traceback.print_exc()\n",
    "            break\n",
    "\n",
    "except Exception:\n",
    "    print(\"[FATAL] client crashed during initialization\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "finally:\n",
    "    print(\"[INFO] shutting down client...\")\n",
    "    safe_close(fwd_sock, \"fwd_sock\")\n",
    "    safe_close(bwd_sock, \"bwd_sock\")\n",
    "    print(\"[INFO] client shutdown complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4debd165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([800, 100])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "860bce29",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fwd_sock' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfwd_sock\u001b[49m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m      2\u001b[0m bwd_sock\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fwd_sock' is not defined"
     ]
    }
   ],
   "source": [
    "fwd_sock.close()\n",
    "bwd_sock.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30c241c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 100, 100])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1666e2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinyllava",
   "language": "python",
   "name": "tinyllava"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
